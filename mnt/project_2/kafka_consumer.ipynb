{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6565e3f8",
   "metadata": {},
   "source": [
    "# Analysing New York City Taxi Data with Spark Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "55974225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "from delta import configure_spark_with_delta_pip\n",
    "\n",
    "\n",
    "spark = configure_spark_with_delta_pip(\n",
    "    SparkSession.builder.appName(\"MyApp\").config(\n",
    "        \"spark.jars.packages\", \n",
    "        \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.0\"\n",
    "    ).config(\n",
    "        \"spark.sql.extensions\", \n",
    "        \"io.delta.sql.DeltaSparkSessionExtension\"\n",
    "    ).config(\n",
    "        \"spark.sql.catalog.spark_catalog\", \n",
    "        \"org.apache.spark.sql.delta.catalog.DeltaCatalog\"\n",
    "    ).config(\n",
    "        \"spark.sql.repl.eagerEval.enabled\", True\n",
    "    )\n",
    ").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35005b8",
   "metadata": {},
   "source": [
    "Be sure to start the stream on Kafka!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4e622d5b-ef4d-4d78-abcb-e9edc2305ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, IntegerType, \n",
    "    DoubleType, BooleanType, TimestampType, DateType\n",
    ")\n",
    "\n",
    "schema = StructType(\n",
    "      [\n",
    "        StructField(\"medallion\",          StringType(), False),\n",
    "        StructField(\"hack_licence\",       StringType(), False),\n",
    "        StructField(\"vendor_id\",          StringType(), False),\n",
    "        StructField(\"rate_code\",          IntegerType(), False),\n",
    "        StructField(\"store_and_fwd_flag\", StringType(), False),\n",
    "        StructField(\"pickup_datetime\",    StringType(), False),\n",
    "        StructField(\"dropoff_datetime\",   StringType(), False),\n",
    "        StructField(\"passenger_count\",    IntegerType(), False),\n",
    "        StructField(\"trip_time_in_secs\",  IntegerType(), False),\n",
    "        StructField(\"trip_distance\",      DoubleType(), False),\n",
    "        StructField(\"pickup_longitude\",   DoubleType(), False),\n",
    "        StructField(\"pickup_latitude\",    DoubleType(), False),\n",
    "        StructField(\"dropoff_longitude\",  DoubleType(), False),\n",
    "        StructField(\"dropoff_latitude\",   DoubleType(), False),\n",
    "        StructField(\"timestamp\",          TimestampType(), False)\n",
    "      ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "69712d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_server = \"kafka1:9092\" \n",
    "\n",
    "kafka_df = (spark.readStream                        # Get the DataStreamReader\n",
    "  .format(\"kafka\")                                 # Specify the source format as \"kafka\"\n",
    "  .option(\"kafka.bootstrap.servers\", kafka_server) # Configure the Kafka server name and port\n",
    "  .option(\"subscribe\", \"stock\")                       # Subscribe to the \"stock\" Kafka topic \n",
    "  .option(\"startingOffsets\", \"earliest\")           # The start point when a query is started\n",
    "  .option(\"maxOffsetsPerTrigger\", 100)             # Rate limit on max offsets per trigger interval\n",
    "  .load() # Load the DataFrame\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "71b95efd-9ef8-4294-83cb-a8d6e1e23029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_json, col\n",
    "\n",
    "parsed_df = kafka_df.select(\n",
    "    from_json(\n",
    "        col(\"value\").cast(\"string\"), schema\n",
    "    ).alias(\"parsed_value\")\n",
    ").select(\"parsed_value.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b2e6c7fb-fe45-4b36-a8f3-c987e0d612cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"taxi_rides\"\n",
    "checkpoint_path = f\"{table_name}_checkpoints\"\n",
    "\n",
    "query = (parsed_df\n",
    "         .writeStream\n",
    "         .outputMode(\"append\")\n",
    "         .format(\"kafka\")\n",
    "         .option(\"checkpointLocation\", checkpoint_path)\n",
    "         .queryName(table_name)\n",
    "         .start())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54040f9-4180-498f-8aeb-1b088b355e89",
   "metadata": {},
   "source": [
    "The next code block triggers this error:\n",
    "```\n",
    "Py4JJavaError: \n",
    "An error occurred while calling o35.sql.: \n",
    "org.apache.spark.SparkException: \n",
    "Cannot find catalog plugin class for catalog 'spark_catalog': \n",
    "org.apache.spark.sql.delta.catalog.DeltaCatalog.\n",
    "...\n",
    "```\n",
    "Can someone figure out why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3bcdd9e3-1195-4280-bfbc-9dd80891d824",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = spark.sql(f\"SELECT * FROM {table_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a46c68-44ab-4e3a-90fb-d334423e4acc",
   "metadata": {},
   "source": [
    "## The project starts here\n",
    "\n",
    "You can create a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24187ef-e5b4-4fa7-bab5-60aa94412a05",
   "metadata": {},
   "source": [
    "## [Query 1] Utilization over a window of 5, 10, and 15 minutes per taxi/driver. This can be computed by computing the idle time per taxi. How does it change? Is there an optimal window?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b2d7ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6746caef-fc7c-4d0e-98df-cdd6046393eb",
   "metadata": {},
   "source": [
    "## [Query 2] The average time it takes for a taxi to find its next fare(trip) per destination borough. This can be computed by finding the time difference, e.g. in seconds, between the trip's drop off and the next trip's pick up within a given unit of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea404b-fc76-48f9-83d9-5946617863de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember you can register another stream\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8268c285-d55c-4be3-8e5a-e7ddebb14153",
   "metadata": {},
   "source": [
    "## [Query 3] The number of trips that started and ended within the same borough in the last hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e7ad21-59c2-4d4c-befe-9d1ceedbb74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember you can register another stream\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d0d685-c3ed-4b7d-8ebc-c3174ba55645",
   "metadata": {},
   "source": [
    "## [Query 4] The number of trips that started in one borough and ended in another one in the last hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f3578b-1960-4969-801b-adc2f45493a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
