{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6565e3f8",
   "metadata": {},
   "source": [
    "# Reading NYC taxi rides from Kafka using Spark Streaming\n",
    "\n",
    "## PySpark setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59be8b0a-fe76-42f2-b521-d8ce4673d7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "from delta import *\n",
    "from delta.tables import *\n",
    "\n",
    "\n",
    "builder = (\n",
    "    SparkSession.builder.appName(\"NYC_taxi_kafka\")\n",
    "    .config(\"spark.sql.extensions\", \n",
    "            \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \n",
    "            \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    .config(\"spark.jars.packages\", \n",
    "            \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.0\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    ")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c69c7f-e61c-4a87-9281-7f38219bf1bc",
   "metadata": {},
   "source": [
    "## Define schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e622d5b-ef4d-4d78-abcb-e9edc2305ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, IntegerType, \n",
    "    DoubleType, BooleanType, TimestampType, DateType\n",
    ")\n",
    "\n",
    "schema = StructType(\n",
    "      [\n",
    "        StructField(\"medallion\",          StringType(), False),\n",
    "        StructField(\"hack_licence\",       StringType(), False),\n",
    "        StructField(\"vendor_id\",          StringType(), False),\n",
    "        StructField(\"rate_code\",          IntegerType(), False),\n",
    "        StructField(\"store_and_fwd_flag\", StringType(), False),\n",
    "        StructField(\"pickup_datetime\",    StringType(), False),\n",
    "        StructField(\"dropoff_datetime\",   StringType(), False),\n",
    "        StructField(\"passenger_count\",    IntegerType(), False),\n",
    "        StructField(\"trip_time_in_secs\",  IntegerType(), False),\n",
    "        StructField(\"trip_distance\",      DoubleType(), False),\n",
    "        StructField(\"pickup_longitude\",   DoubleType(), False),\n",
    "        StructField(\"pickup_latitude\",    DoubleType(), False),\n",
    "        StructField(\"dropoff_longitude\",  DoubleType(), False),\n",
    "        StructField(\"dropoff_latitude\",   DoubleType(), False),\n",
    "        StructField(\"timestamp\",          TimestampType(), False)\n",
    "      ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35005b8",
   "metadata": {},
   "source": [
    "## Read Kafka stream and parse JSON\n",
    "\n",
    "Be sure to start the stream from the notebook `kafka_producer.ipynb`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69712d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_json, col\n",
    "\n",
    "kafka_server = \"kafka1:9092\" \n",
    "\n",
    "kafka_df = (spark.readStream                        # Get the DataStreamReader\n",
    "  .format(\"kafka\")                                 # Specify the source format as \"kafka\"\n",
    "  .option(\"kafka.bootstrap.servers\", kafka_server) # Configure the Kafka server name and port\n",
    "  .option(\"subscribe\", \"stock\")                       # Subscribe to the \"stock\" Kafka topic \n",
    "  .option(\"startingOffsets\", \"earliest\")           # The start point when a query is started\n",
    "  .option(\"maxOffsetsPerTrigger\", 100)             # Rate limit on max offsets per trigger interval\n",
    "  .load() # Load the DataFrame\n",
    ")\n",
    "\n",
    "parsed_df = kafka_df.select(\n",
    "    from_json(\n",
    "        col(\"value\").cast(\"string\"), schema\n",
    "    ).alias(\"parsed_value\")\n",
    ").select(\"parsed_value.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07bf182-b64f-42f2-895f-23a433d7c762",
   "metadata": {},
   "source": [
    "## Write data into a Delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2e6c7fb-fe45-4b36-a8f3-c987e0d612cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data exists\n"
     ]
    }
   ],
   "source": [
    "import time, os\n",
    "\n",
    "table_name = \"taxi_rides\"\n",
    "checkpoint_path = \"streaming/orders/_checkpoint\" \n",
    "output_path = f\"spark-warehouse/{table_name}\"\n",
    "\n",
    "query = (parsed_df.writeStream\n",
    "  .outputMode(\"append\")\n",
    "  .format(\"delta\")\n",
    "  .queryName(f\"{table_name}_query\")\n",
    "  .trigger(processingTime=\"5 second\")\n",
    "  .option(\"checkpointLocation\", checkpoint_path)\n",
    "  .start(output_path) \n",
    ")\n",
    "\n",
    "# if you create the table metastore before any data exists then \n",
    "# the stream will result in an error as the table is generated with empty schema\n",
    "def create_table_if_exists(output_path, table_name):\n",
    "    data_exists = False\n",
    "    # you can replace this with while, currently timeouts after about 60 seconds\n",
    "    for _ in range(60):\n",
    "        try:\n",
    "            time.sleep(1)\n",
    "            files = os.listdir(output_path)\n",
    "            for file in files:\n",
    "                if \".parquet\" in file:\n",
    "                    if len(os.listdir(f\"{output_path}/_delta_log\"))>0:\n",
    "                        print(\"data exists\")\n",
    "                        data_exists = True\n",
    "                        break\n",
    "            if data_exists:\n",
    "                # table metastore is created once there is some data (.parquet) in the directory\n",
    "                spark.sql(f\"CREATE TABLE IF NOT EXISTS {table_name} USING DELTA LOCATION '{table_name}'\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "create_table_if_exists(output_path, table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b518122-75d6-4faf-bf90-d18b21fe56f1",
   "metadata": {},
   "source": [
    "If you need to run the query again, you need to stop it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adac87d9-8909-4cd6-96af-15198d04ff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e88cfd42-35ab-4441-aec8-8ece95aaf828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>medallion</th><th>hack_licence</th><th>vendor_id</th><th>rate_code</th><th>store_and_fwd_flag</th><th>pickup_datetime</th><th>dropoff_datetime</th><th>passenger_count</th><th>trip_time_in_secs</th><th>trip_distance</th><th>pickup_longitude</th><th>pickup_latitude</th><th>dropoff_longitude</th><th>dropoff_latitude</th><th>timestamp</th></tr>\n",
       "<tr><td>89D227B655E5C82AE...</td><td>BA96DE419E711691B...</td><td>CMT</td><td>1</td><td>N</td><td>2013-01-01 15:11:48</td><td>2013-01-01 15:18:10</td><td>4</td><td>382</td><td>1.0</td><td>-73.978165</td><td>40.757977</td><td>-73.989838</td><td>40.751171</td><td>2024-05-23 12:11:54</td></tr>\n",
       "<tr><td>0BD7C8F5BA12B88E0...</td><td>9FD8F69F0804BDB55...</td><td>CMT</td><td>1</td><td>N</td><td>2013-01-06 00:18:35</td><td>2013-01-06 00:22:54</td><td>1</td><td>259</td><td>1.5</td><td>-74.006683</td><td>40.731781</td><td>-73.994499</td><td>40.75066</td><td>2024-05-23 12:11:54</td></tr>\n",
       "<tr><td>0BD7C8F5BA12B88E0...</td><td>9FD8F69F0804BDB55...</td><td>CMT</td><td>1</td><td>N</td><td>2013-01-05 18:49:41</td><td>2013-01-05 18:54:23</td><td>1</td><td>282</td><td>1.1</td><td>-74.004707</td><td>40.73777</td><td>-74.009834</td><td>40.726002</td><td>2024-05-23 12:11:55</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+--------------------+---------+---------+------------------+-------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+-------------------+\n",
       "|           medallion|        hack_licence|vendor_id|rate_code|store_and_fwd_flag|    pickup_datetime|   dropoff_datetime|passenger_count|trip_time_in_secs|trip_distance|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|          timestamp|\n",
       "+--------------------+--------------------+---------+---------+------------------+-------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+-------------------+\n",
       "|89D227B655E5C82AE...|BA96DE419E711691B...|      CMT|        1|                 N|2013-01-01 15:11:48|2013-01-01 15:18:10|              4|              382|          1.0|      -73.978165|      40.757977|       -73.989838|       40.751171|2024-05-23 12:11:54|\n",
       "|0BD7C8F5BA12B88E0...|9FD8F69F0804BDB55...|      CMT|        1|                 N|2013-01-06 00:18:35|2013-01-06 00:22:54|              1|              259|          1.5|      -74.006683|      40.731781|       -73.994499|        40.75066|2024-05-23 12:11:54|\n",
       "|0BD7C8F5BA12B88E0...|9FD8F69F0804BDB55...|      CMT|        1|                 N|2013-01-05 18:49:41|2013-01-05 18:54:23|              1|              282|          1.1|      -74.004707|       40.73777|       -74.009834|       40.726002|2024-05-23 12:11:55|\n",
       "+--------------------+--------------------+---------+---------+------------------+-------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+-------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.table(table_name).limit(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a46c68-44ab-4e3a-90fb-d334423e4acc",
   "metadata": {},
   "source": [
    "## The project starts here\n",
    "\n",
    "You can create a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24187ef-e5b4-4fa7-bab5-60aa94412a05",
   "metadata": {},
   "source": [
    "## [Query 1] Utilization over a window of 5, 10, and 15 minutes per taxi/driver. This can be computed by computing the idle time per taxi. How does it change? Is there an optimal window?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b2d7ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6746caef-fc7c-4d0e-98df-cdd6046393eb",
   "metadata": {},
   "source": [
    "## [Query 2] The average time it takes for a taxi to find its next fare(trip) per destination borough. This can be computed by finding the time difference, e.g. in seconds, between the trip's drop off and the next trip's pick up within a given unit of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea404b-fc76-48f9-83d9-5946617863de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember you can register another stream\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8268c285-d55c-4be3-8e5a-e7ddebb14153",
   "metadata": {},
   "source": [
    "## [Query 3] The number of trips that started and ended within the same borough in the last hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e7ad21-59c2-4d4c-befe-9d1ceedbb74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember you can register another stream\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d0d685-c3ed-4b7d-8ebc-c3174ba55645",
   "metadata": {},
   "source": [
    "## [Query 4] The number of trips that started in one borough and ended in another one in the last hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f3578b-1960-4969-801b-adc2f45493a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
